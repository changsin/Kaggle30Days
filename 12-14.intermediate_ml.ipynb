{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intermediate_ml",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changsin/Kaggle30Days/blob/main/12-14.intermediate_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0Uzu3IA-3Ef"
      },
      "source": [
        "# Intermediate Machine Learning\n",
        "## Day 12 of Kaggle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNvy2O7zWjmD"
      },
      "source": [
        "## Missing values\n",
        "Here is a handy way to check missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTzp73gpB7Im"
      },
      "source": [
        "# Shape of training data (num_rows, num_columns)\n",
        "print(X_train.shape)\n",
        "\n",
        "# Number of missing values in each column of training data\n",
        "missing_val_count_by_column = (X_train.isnull().sum())\n",
        "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nizgOx6QTs2D"
      },
      "source": [
        "## Categorical variables\n",
        "\n",
        "- To select only numerical columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TxY8A5iTz2w"
      },
      "source": [
        " [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4wJsUJVVyHS"
      },
      "source": [
        "- to apply OrdinalEncoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lszu-TooVvos"
      },
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# Drop categorical columns that will not be encoded\n",
        "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
        "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
        "\n",
        "# Apply ordinal encoder \n",
        "# Your code here\n",
        "# Apply ordinal encoder to each column with categorical data\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "label_X_train[good_label_cols] = ordinal_encoder.fit_transform(label_X_train[good_label_cols])\n",
        "label_X_valid[good_label_cols] = ordinal_encoder.transform(label_X_valid[good_label_cols])\n",
        "\n",
        "# Check your answer\n",
        "step_2.b.check()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKG8OA6-Tfo1"
      },
      "source": [
        "### Submission\n",
        "\n",
        "The submission required cleaning up the test data: i.e., imputing NaN values from certain columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW3K4RdbTt5U"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "final_imputer = SimpleImputer(strategy='most_frequent')\n",
        "imputed_X_train = pd.DataFrame(final_imputer.fit_transform(X_train))\n",
        "imputed_X_test = pd.DataFrame(final_imputer.transform(X_test))\n",
        "imputed_X_test.columns = X_test.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8qr7TLcTyUc"
      },
      "source": [
        "OH_cols_test = pd.DataFrame(OH_encoder.transform(imputed_X_test[low_cardinality_cols]))\n",
        "OH_cols_test.index = imputed_X_test.index\n",
        "num_X_test = imputed_X_test.drop(object_cols, axis=1)\n",
        "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
        "\n",
        "OH_X_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "engOcNWvUA_M"
      },
      "source": [
        "- Check to make sure that there are no missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqC2Pf9AT_91"
      },
      "source": [
        "missing_val_count_by_column = (OH_X_test.isnull().sum())\n",
        "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HKa-C7EUNJd"
      },
      "source": [
        "- This step is not necessary since ordinal encoder is not the one we used, but leaving here just for illustration purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ36UWRUUKKV"
      },
      "source": [
        "drop_X_test = X_test[[cname for cname in X_test.columns if X_test[cname].dtype in ['int64', 'float64']]]\n",
        "label_X_test = imputed_X_test.drop(bad_label_cols, axis=1)\n",
        "label_X_test[good_label_cols] = ordinal_encoder.transform(label_X_test[good_label_cols])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-2bF6XLUl10"
      },
      "source": [
        "- Finally train, predict, and save for submission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-5Q_5syTnet"
      },
      "source": [
        "# Define and fit model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
        "model.fit(OH_X_train, y_train)\n",
        "\n",
        "# Get validation predictions and MAE\n",
        "preds_test = model.predict(OH_X_test)\n",
        "\n",
        "# Save test predictions to file\n",
        "output = pd.DataFrame({'Id': X_test.index,\n",
        "                       'SalePrice': preds_test})\n",
        "output.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}